{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Competition: https://www.kaggle.com/competitions/diabetes-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "data.fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 614 entries, 0 to 613\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   p_id                   614 non-null    int64  \n",
      " 1   no_times_pregnant      614 non-null    int64  \n",
      " 2   glucose_concentration  614 non-null    int64  \n",
      " 3   blood_pressure         614 non-null    int64  \n",
      " 4   skin_fold_thickness    614 non-null    int64  \n",
      " 5   serum_insulin          614 non-null    int64  \n",
      " 6   bmi                    614 non-null    float64\n",
      " 7   diabetes pedigree      614 non-null    float64\n",
      " 8   age                    614 non-null    int64  \n",
      " 9   diabetes               614 non-null    int64  \n",
      "dtypes: float64(2), int64(8)\n",
      "memory usage: 48.1 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diabetes\n",
       "0    400\n",
       "1    214\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.diabetes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['p_id', 'no_times_pregnant', 'glucose_concentration', 'blood_pressure',\n",
       "       'skin_fold_thickness', 'serum_insulin', 'bmi', 'diabetes pedigree',\n",
       "       'age', 'diabetes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importance:\n",
      "Index(['no_times_pregnant', 'glucose_concentration', 'blood_pressure',\n",
      "       'skin_fold_thickness', 'serum_insulin', 'bmi', 'diabetes pedigree',\n",
      "       'age', 'diabetes'],\n",
      "      dtype='object')\n",
      "[0.0826375  0.27092473 0.08921212 0.06663935 0.06824126 0.16278637\n",
      " 0.12889934 0.13065933]\n",
      "\n",
      "Selected features:\n",
      "Index(['glucose_concentration', 'bmi', 'diabetes pedigree', 'age'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "data.drop('p_id', axis=1, inplace=True)\n",
    "\n",
    "X = data.drop('diabetes', axis=1)\n",
    "y = data['diabetes']\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=7, n_jobs=-1)\n",
    "classifier.fit(X, y)\n",
    "\n",
    "print(f\"Importance:\\n{data.columns}\\n{classifier.feature_importances_}\\n\")\n",
    "\n",
    "sfm = SelectFromModel(classifier, threshold=0.1)\n",
    "sfm.fit(X, y)\n",
    "\n",
    "X_important = sfm.transform(X)\n",
    "\n",
    "feature_names = X.columns[sfm.get_support()]\n",
    "\n",
    "print('Selected features:')\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classification(Random Forest) and check accuracy using train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7804878048780488\n",
      "Accuracy for each fold: [0.74       0.81632653 0.67346939 0.7755102  0.71428571 0.81632653\n",
      " 0.75510204 0.67346939 0.71428571 0.73469388]\n",
      "average accuracy: 0.7413469387755103\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_important, y, test_size=0.2, random_state=7)\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=7, shuffle=True)\n",
    "scores = cross_val_score(classifier, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "print(f\"Accuracy for each fold: {scores}\")\n",
    "print(f\"average accuracy: {scores.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descison Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6910569105691057\n",
      "Accuracy for each fold: [0.7        0.79591837 0.67346939 0.75510204 0.63265306 0.7755102\n",
      " 0.75510204 0.67346939 0.63265306 0.6122449 ]\n",
      "average accuracy: 0.7006122448979591\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "d_classifier = DecisionTreeClassifier(random_state=7, )\n",
    "d_classifier.fit(X_train, y_train)\n",
    "y_pred = d_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "k_scores = cross_val_score(d_classifier, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "print(f\"Accuracy for each fold: {k_scores}\")\n",
    "print(f\"average accuracy: {k_scores.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8292682926829268\n",
      "Accuracy for each fold: [0.78       0.75510204 0.57142857 0.71428571 0.75510204 0.79591837\n",
      " 0.67346939 0.73469388 0.69387755 0.67346939]\n",
      "average accuracy: 0.714734693877551\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "k_classifier = KNeighborsClassifier(n_neighbors=9)\n",
    "\n",
    "k_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = k_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "k_scores = cross_val_score(k_classifier, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "print(f\"Accuracy for each fold: {k_scores}\")\n",
    "print(f\"average accuracy: {k_scores.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7804878048780488\n",
      "Accuracy for each fold: [0.7        0.81632653 0.65306122 0.7755102  0.7755102  0.85714286\n",
      " 0.71428571 0.73469388 0.65306122 0.71428571]\n",
      "average accuracy: 0.7393877551020408\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "g_classifier = GradientBoostingClassifier(n_estimators=180, learning_rate=0.01, max_depth=1, random_state=7)\n",
    "g_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = g_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "k_scores = cross_val_score(g_classifier, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "print(f\"Accuracy for each fold: {k_scores}\")\n",
    "print(f\"average accuracy: {k_scores.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate result.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Patrick\\Documents\\GitHub\\DataMiningNTNU\\env\\lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "test_data = test[feature_names]\n",
    "\n",
    "predictions = g_classifier.predict(test_data)\n",
    "\n",
    "result = pd.DataFrame({\n",
    "    'p_id': test['p_id'].values,\n",
    "    'diabetes': predictions\n",
    "})\n",
    "\n",
    "result.to_csv('result.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
